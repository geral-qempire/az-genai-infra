---
title: 'README'
description: 'Quick overview of module usage, inputs, outputs and requirements.'
icon: 'circle-info'
---

## 1. Module
Create an Azure Monitor metric alert for Azure OpenAI processed inference tokens (total) split by model deployment:
- Metric: `TokenTransaction` (Processed Inference Tokens)
- Namespace: `Microsoft.CognitiveServices/accounts`
- Aggregation: `Total`
- Dimension: `ModelDeploymentName` (defaults to all deployments using `*`)
- Operator: GreaterThan
- Evaluation Frequency: 5 minutes (PT5M)
- Time Window: 1 hour (PT1H)
- Severity: 3
- Default Threshold: 10000000

## 2. Usage
```hcl main.tf
module "ai_processed_inference_tokens_alert" {
  source = "../ai-services-tok"

  # Optional name. If omitted, defaults to: alrt-tok-<resource-name>
  # name = "alrt-tok-openai-prod"

  resource_group_name = "rg-observability-prod"
  scopes              = [module.ai_services.ai_services_id] # Microsoft.CognitiveServices/accounts

  # Default threshold is 10,000,000 tokens
  # threshold = 10000000

  # Split by model deployment name(s)
  model_deployment_names = [
    "gpt-4o-mini",
    "text-embedding-3-large"
  ]

  # Optional settings
  description   = "Azure OpenAI processed tokens exceeded threshold over the last 24 hours"
  enabled       = true
  auto_mitigate = true

  action_group_ids = [
    module.action_group.action_group_id
  ]

  tags = {
    environment = "prod"
    project     = "acme"
  }
}
```

Wildcard example (all model deployments):
```hcl main.tf
module "ai_processed_inference_tokens_alert_all" {
  source = "../ai-services-tok"

  resource_group_name = "rg-observability-prod"
  scopes              = [module.ai_services.ai_services_id]

  # Splits by all current and future model deployments
  model_deployment_names = ["*"]
}
```

## 3. Inputs
| Name | Type | Default | Required | Description |
|------|------|---------|:--------:|-------------|
| `name` | `string` | `null` | no | Name of the metric alert. Defaults to `alrt-tok-<resource-name>`. |
| `resource_group_name` | `string` | n/a | yes | Resource group in which to create the alert. |
| `scopes` | `list(string)` | n/a | yes | List of Azure AI Services account resource IDs (Microsoft.CognitiveServices/accounts). |
| `threshold` | `number` | `10000000` | no | Token threshold. Fires when total tokens over the window exceed this value. |
| `model_deployment_names` | `list(string)` | `["*"]` | no | Model deployment names to filter on `ModelDeploymentName` dimension. |
| `description` | `string` | `null` | no | Custom description for the alert. |
| `enabled` | `bool` | `true` | no | Whether the alert is enabled. |
| `auto_mitigate` | `bool` | `true` | no | Whether the alert should auto mitigate when conditions clear. |
| `action_group_ids` | `list(string)` | `[]` | no | Action Group IDs to notify when the alert fires. |
| `metric_name` | `string` | `"TokenTransaction"` | no | Advanced: override the metric name if needed. |
| `tags` | `map(string)` | `{}` | no | Tags to apply to the metric alert resource. |

## 4. Outputs
| Name | Description |
|------|-------------|
| `id` | Resource ID of the metric alert. |
| `name` | Name of the metric alert. |

## 5. Requirements
- Terraform `>= 1.12.1, < 2.0.0`
- AzureRM provider `~> 4.38`
- Existing Resource Group
- Existing Azure AI Services (Cognitive Services) account with Azure OpenAI enabled


